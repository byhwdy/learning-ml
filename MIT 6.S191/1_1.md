good afternoon everyone thank you all
for joining us my name is Alexandra
Meany and one of the course organizers
for six s-191 this is mi t--'s official
course on introduction to deep learning
and this is actually the third year that
we're offering this course and we've got
a really good one in store for you this
year with a lot of awesome updates so I
really hope that you enjoy it
so what is this course all about this is
a one-week intensive boot camp on
everything deep learning
you'll get up close and personal with
some of the foundations of the
algorithms driving this remarkable field
and you'll actually learn how to build
some intelligent algorithms capable of
solving incredibly complex problems so
over the past couple years deep learning
has revolutionized many aspects of
research and industry including things
like autonomous vehicles medicine and
healthcare reinforcement learning
generative modeling robotics and a whole
host of other applications like natural
language processing finance and security
but before we talk about that I think we
should start by taking a step back and
talking about something at the core of
this class which is intelligence what is
intelligence well I like to define
intelligence as the ability to process
information to inform future decisions
the field of artificial intelligence is
actually building algorithms artificial
algorithms to do exactly that
bit process information to inform future
predictions now machine learning is
simply a subset of artificial
intelligence or AI that actually focuses
on teaching an algorithm how to take
information and do this without
explicitly being told the sequence of
rules but instead learn the sequence of
patterns from the data itself deep
learning is simply a subset of machine
learning which takes this idea one step
further and actually tries to extract
these patterns automatically from raw
data without being needed without the
need to for the human to actually come
in and annotate these rules that the
system needs to learn
and that's what this class is all about
teaching algorithms how to learn a task
from raw data we want to provide you
with a solid foundation that so that you
can learn how these algorithms work
under the hood and with the practical
skills so that you can actually
implement these algorithms from scratch
using deep learning frameworks like
tensor flow which is the current most
popular deep learning framework that you
can code some of neural networks and
deep learning model and other deep
learning models we have an amazing set
of lectures lined up for you this week
including today which will kick off an
introduction on neural networks and
sequence based modeling which you'll
hear about in the second part of the
class tomorrow we'll cover some about
some stuff about computer vision and
deep generative modeling and the day
after that we'll talk even about
reinforcement learning and end on some
of the challenges and limitations of the
current deep learning approaches and and
kind of touch on how we can move forward
as a field past these challenges we'll
also spend the final two days hearing
from some guest lectures from top a AI
researchers these are bound to be
extremely interesting though we have
speakers from Nvidia IBM Google coming
to give talks so I highly recommend
attending these as well and finally the
class will conclude with some final
project presentations from students like
you and the audience will where you'll
present some final projects for this
class and then we'll end on an award
ceremony to celebrate so as you might
have seen or heard already this class is
offered for credit you can take this
class for grade and if you're taking
this class for grade you have two
options to fulfill your grade
requirement first option is that you can
actually do a project proposal where you
will present your project on the final
day of class that's what I was saying
before on Friday you can present your
project and this is just a three minute
presentation we'll be very strict on the
time here and we realized that one week
is a super short time to actually come
up with a deep learning project so we're
not going to actually be judging you on
the results
you create during this week instead what
we're looking for is the novelty of the
ideas and how well you can present it
given such a short amount of time in
three minutes and we kind of think it's
like an art to being able to present
something in just three minutes so we
kind of want to hold you to that tight
time schedule and kind of enforce it
very tightly just so that you're forced
to really think about what is the core
idea that you want to present to us on
Friday your projects your presentations
will be judged by a panel of judges and
will be awarding GPUs and some home
Google home AI assistants this year
we're offering three NVIDIA GPUs each
one worth over $1,000 some of you know
these GPUs are the backbone of doing
cutting-edge deep learning research and
it's really foundational or essential if
you want to be doing this kind of
research so we're really happy that we
can offer you these types this type of
hardware the second option if you don't
want to do the project presentation but
you still want to receive credit for
this class you can do the second option
which is a little more boring in my
opinion but you can write a one-page
review of a deep learning paper and this
will be doing the last day of class and
this is for people I don't want to do
the project presentation but you still
want to get credit for this class please
post to Piazza if you have questions
about the labs that we'll be doing today
or any of the future days if you have
questions about the course in general
there's course information on the
website enter deep learning com
along with announcements digital
recordings as well as slides for these
classes today's slides are already
released so you can find everything
online and of course if you have any
questions you can email us at intro to
deep learning - staff at MIT edu this
course has an incredible team that you
can reach out to in case you have any
questions or issues about anything so
please don't hesitate to reach out and
finally we want to give a huge thanks to
all of the sponsors that made this
course possible so now let's start with
the fun stuff and actually let's start
by asking ourselves a question
why do we even care about this class why
did you all come here today what is why
do we care about deep learning well
traditional machine learning algorithms
typically define sets of rules or
features that you want to extract from
the data usually these are hand
engineered features and they tend to be
extremely brittle in practice
now the key idea is a key insight of
deep learning is that let's not hand
engineer these features instead let's
learn them directly from raw data that
is can we learn in order to detect the
face we can first detect the edges in
the picture compose these edges together
to start detecting things like eyes
mouth and nose and then composing these
features together to detect higher-level
structures in the face and and this is
all performed in a hierarchical manner
so the question of deep learning is how
can we go from raw image pixels or raw
data in general to a more complex and
complex representation as the data flows
through the model and actually the
fundamental fundamental building blocks
of deep learning have existed for
decades and their underlying algorithms
have been studied for many years even
before that so why are we studying this
now well for one data has become so
prevalent in today's society we're
living in the age of big data where we
have more access to data than ever
before and these models are hungry for
data so we need to feed them with all
the data and a lot of this datasets that
we have available like computer vision
datasets natural language processing
datasets this raw amount of data was
just not available when these algorithms
were created second these algorithms
require or these albums are massively
parallel lies about their core at their
most fundamental building blocks that
you'll learn today they're massively
paralyzed Abul and this means that they
can benefit tremendously from very
specialized hardware such as GPUs and
again technology like these GPUs simply
did not exist in the decades that deep
learning or the foundations of deep
learning were devil
and finally due to open-source tool
boxes like tensorflow which will you
learn to use in this class building and
deploying these models has become more
streamlined than ever before it is
becoming increasingly and increasingly
easy to abstract away all of the details
and build a neural network and train a
neural network and then deploy that
neural network in practice to solve a
very complex problem in just tens of
lines of code you can solve you can
create a facial classifier that's
capable of recognizing very complex
faces from the environment so let's
start with the most fundamental building
block of deep learning and that's the
fundamental building block that makes up
a neural network and that is a neuron so
what is the neuron in deep learning we
call it a perceptron and how does it
work so the idea of a perceptron or a
single neuron is very simple let's start
by talking about and describing the
feed-forward information of information
through that model we define a set of
inputs x1 through XM which you can see
on the left hand side and each of these
inputs are actually multiplied by a
corresponding weight w1 through WM so
you can imagine if you have x1 you x w1
you have x2 you x w2 and so on you take
all of those multiplications and you add
them up so these come together in a
summation and then you pass this
weighted sum through a nonlinear
activation function to produce a final
output which we'll call Y so that's
really simple let's I actually left out
one detail in that previous slide so
I'll add it here now we also have this
other turn term this green term which is
a bias term which allows you to shift
your activation function left and right
and now on the right side you can kind
of see this diagram illustrated as a
mathematical formula as a single
equation we can actually rewrite this
now using linear algebra using vectors
dot products and matrices so let's do
that so now
is a vector of our inputs x1 through M
so instead of now a single number X
capital X is a vector of all of the
inputs capital W is a vector of all of
the weights 1 through m and we can
simply take their weighted sum by taking
the dot product between these two
vectors then we add our bias like I said
before or biased now is a single number
W not and applying that non linear term
so the nonlinear term transfers that
transforms that scalar input to another
scalar output Y so you might now be
wondering what is this thing that I've
been referring to as an activation
function I've mentioned it a couple
times I called it by a couple different
names first was a nonlinear function
then was an activation function what is
it
so one common example of a nonlinear
activation function is called the
sigmoid function and you can see one
here defined on the bottom right this is
a function that takes as input any real
number and outputs a new number between
0 and 1 so you can see it's essentially
collapsing your input between this range
of 0 and 1 this is just one example of
an activation function but there are
many many many activation functions used
in neural networks
here are some common ones and throughout
this presentation you'll see these
tensorflow code blocks on the bottom
like like this for example and I'll just
be using these as a as a way to kind of
bridge the gap between the theories that
you'll learn in this class with some of
the tensor flow that you'll be
practicing in the labs later today and
through the week so the sigmoid function
like I mentioned before which you can
see on the left-hand side is useful for
modeling probabilities because like I
said it collapses your your input to
between 0 & 1
since probabilities are modeled between
0 & 1 this is actually the perfect
activation function for the end of your
neural network if you want to predict
probability distributions at the end
another popular option is the r lu
function which you can see on the far
right-hand side this function is an
extremely simple one to compute it's
piecewise linear and it's very popular
because it's so easy to compute but
has this non-linearity at Z equals zero
so at Z less than 0 this function equals
0 and at Z greater than 0 it just equals
the input and because of this
non-linearity it's still able to capture
all of the great properties of
activation functions while still being
extremely simple to compute and now I
want to talk a little bit about why do
we use activation functions at all I
think a great part of this class is to
actually ask questions and not take
anything for granted so if I tell you we
need an activation function the first
thing that should come to your mind is
well why do we need that activation
function so activation functions the
purpose of activation functions is to
introduce nonlinearities into the
network this is extremely important in
deep learning or in machine learning in
general because in real life data is
almost always very nonlinear imagine I
told you to separate here the green from
the red points you might think that's
easy but then what if I told you you had
to only use a single line to do it
well now it's impossible that actually
makes the problem not only really hard
like I said it makes it impossible in
fact if you use linear activation
functions in a neural network no matter
how deep or wide your neural network is
no matter how many neurons it has this
is the best that I will be able to do
produce a linear decision boundary
between the red and the green points and
that's because it's using linear
activation functions when we introduce a
nonlinear activation function that
allows us to approximate arbitrarily
complex functions and draw arbitrarily
complex decision boundaries in this
feature space and that's exactly what
makes neural networks so powerful in
practice so let's understand this with a
simple example imagine I give you a
trains Network with weights W on the top
here so W 0 is 1 and let's say W 0 is 1
the W vector is 3 negative 2 so this is
a trained neural network and I want to
feed in a new input to this network well
how do we compute the output remember
from before it's the dot product we add
our bias and we compute a non-linearity
there's three steps
so let's take a look at what's going on
here what's inside of this nonlinear
function the input to the nonlinear
function well this is just a 2d line in
fact we can actually plot this 2d line
in what we call the feature space so on
the x axis you can see X 1 which is the
first input and on the y axis you can
see X 2 which is the second input this
neural network has two inputs we can
plot the line when it is equal to zero
and you can actually see it in the
feature space here if I give you a new
point a new input to this neural network
you can also plot this new point in the
same feature space so here's the point
negative 1 2 you can plot it like this
and actually you can compute the output
by plugging it into this equation that
we created before this line if we plug
it in we get 1 minus 3 minus 4 right
which equals minus 6 that's the input to
our activation function and then when we
feed it through our activation function
here I'm using sigmoid again for example
our final output is zero point zero zero
two ok what does that number mean let's
go back to this illustration of the
feature space again what this feature
space is doing is essentially dividing
the space into two hyperplanes remember
that the sigmoid function outputs values
between 0 and 1 and at z equals 0 when
the input to the sigmoid is 0 the output
of the sigmoid is 0.5 so essentially
you're splitting your space into two
planes one where Z is greater than zero
and one more Z is less than zero and one
where Y is greater than 0.5 and one
where Y is less than 0.5 the two are
synonymous but when we're dealing with
small dimensional input data like here
we're dealing with only two dimensions
we can make these beautiful plots and
these are very valuable and actually
visualizing the learning algorithm
visualizing how our output is relating
to our input we're gonna find very soon
that we can't really do this for all
problems because while here we're
dealing with only two inputs in
practical applications and deep neural
networks we're gonna be dealing with
hundreds thousands or even millions of
inputs to the network
at any given time and then drawing one
of these plots in thousand dimensional
space is going to become pretty tough so
now that we have an idea of the
perceptron a single neuron let's start
by building neural networks from the
ground up using one neuron and seeing
how this all comes together let's
revisit our diagram of the perceptron if
there's a few things that you remember
from this class I want to remember this
so there's three steps to computing the
output of a perceptron dot product add a
bias taking non-linearity three steps
let's simplify the diagram a little bit
I just got rid of the bias
I removed the weights just for
simplicity to keep things simple and
just note here that I'm writing Z as the
input to the to the activation function
so this is the weighted combination
essentially of your inputs Y is then
taking the activation function with
input Z so the final output like I said
Y is is on the right-hand side here and
it's the activation function applied to
this weighted sum if we want to define a
multi output neural network now all we
have to do is add another perceptron to
this picture now we have two outputs
each one is a normal perceptron like we
defined before no nothing extra and each
one is taking all the inputs from the
left-hand side computing this weighted
sum adding a bias and passing it through
an activation function let's keep going
now let's take a look at a single
layered neural network this is one where
we have a single hidden layer between
our inputs and our outputs we call it a
hidden layer because unlike the input
and the output which are strictly
observable or hidden layers learned so
we don't explicitly enforce any behavior
on the hidden layer and that's why we
call it hidden in that sense since we
now have a transformation from the
inputs to the hidden layer and hidden
layer to the outputs we're going to need
two weight matrices so we're going to
call it W one to go from input to hidden
layer and W two to go from hidden layer
to
output but again the story here's the
same dot product add a bias for each of
the neurons and then compute an
activation function let's zoom in now to
a single hidden hidden unit in this
hidden layer if we look at the single
unit take z2 for example it is just the
same perceptron that we saw before I'm
going to keep repeating myself
we took a dot product with the inputs we
applied a bias and then actually so
since it's Z we had not applied our
activation function yet so it's just a
dot product plus a bias so far if we
took it and took a look at a different
neuron let's say z3 or z4 the idea here
is gonna be the same but we're probably
going to end up with a different value
for Z 3 and C 4 just because the weights
leading from Z 3 to the inputs are going
to be different for each of those
neurons so this picture looks a little
bit messy so let's clean things up a
little bit more and just replace all of
these hidden layers all these lines
between the hidden layers with these
symbols these symbols denote fully
connected layers where each input to the
layer is connected to each output of the
layer another common name for these is
called dense layers and you can actually
write this in tensor flow using just
four lines of code so this neural
network which is a single layered multi
output neural network can be called by
instantiating your inputs feeding those
inputs into a hidden layer like I'm
doing here which is just defined as a
single dense layer and then taking those
hidden outputs feeding that into another
dense layer to produce your outputs the
final model is to find it end to end
with that single line at the end model
of inputs and outputs and that just
essentially connects the graph and to
end so now let's keep building on this
idea now we want to build a deep neural
network what is the deep neural network
well it's just one where we keep
stacking these hidden layers back to
back to back to back to create
increasingly deeper and deeper models
one where the output is computed by
going deeper into the network and
computing these weighted sums over and
over and over again with these
activation functions repeatedly applied
so this is awesome now we have an idea
on how to actually build a neural
network from scratch going all the way
from a single perceptron and we know how
to compose them to create very complex
deep neural networks as well let's take
a look at how we can apply this to a
very real problem that I know a lot of
you probably care about so I was
thinking of a problem potential that
some of you might care about it took me
a while but I think this might be one so
at MIT we care a lot about passing our
classes so I think a very good example
is let's train a neural network to
determine if you're gonna pass your
class so to do this let's start with a
simple two input feature model one
feature is the number of lectures that
you attend the other feature is the
number of hours that you spend on the
final project again since we have two
inputs we can plot this data on a
feature map like we did before green
points here represent previous students
from previous years that pass the class
red points represent students that
failed the class now if you want to find
out if you're gonna pass or fail to
class you can also apply yourself on
this map you spent you came to four
lectures spend five hours on your final
project and you want to know if you're
going to pass or fail and you want to
actually build a neural networks that's
going to learn this look at the old the
the previous people that took the scores
and determine if you all pass or fail as
well so let's do it
we have two inputs one is four one is
five these are fed into a single layered
neural network with three hidden units
and we see that the final output
probability that you will pass this
class is 0.1 or 10% not very good that's
actually really bad news can anyone
guess why this person who actually was
in the part of the feature space it
looked like they were actually in a good
part of this feature space looked like
they were gonna pass the class why did
this neural network give me such a bad
prediction here yeah exactly so the
network was not trained essentially this
network is like a baby that was just
born it has no idea of what lectures are
it doesn't know where final labs are it
doesn't know anything about this world
it's these are just numbers to it it's
been randomly initialized it has
no idea about the problem so we have to
actually train it we have to teach it
how to get the right answer so the first
thing that we have to do is tell the
network when it makes a mistake so that
we can correct it in the future now how
do we do this in neural networks the
loss of a network is actually what
defines when the network makes the wrong
prediction it takes the input and the
predicted output sorry it takes as input
the predicted output and the ground
truth actual output if your predicted
output and your ground truth output are
very close to each other then that
essentially means that your loss is
going to be very low you didn't make a
mistake but if your ground truth output
is very far away from your predicted
output that means that you should have a
very high loss you just have a lot of
error and your network should correct
that so let's assume that we have data
not just from one student now but we
have data from many many different
students passing and failing the class
we now care about how this model does
not just on that one student but across
the entire population of students and we
call this the empirical loss and that's
just the mean of all of the losses for
the individual students we can do it by
literally just computing the mean sorry
just computing the loss for each of
these students and taking their mean
when training a network what we really
want to do is not minimize the loss for
any particular student but we want to
minimize the loss across the entire
training set so if we go back to our
problem on path predicting if you'll
pass or fail to class this is a problem
of binary classification your output is
0 or 1 we already learned that when
outputs are 0 or 1 you're probably going
to want to use a soft max output for
those of you who aren't familiar with
cross entropy this was an idea
introduced actually at MIT and a
master's thesis here over 50 years ago
it's widely used in different areas like
thermodynamics and we use it here in
machine learning as well it's used all
over information theory and what this is
doing here is essentially computing the
loss between this zero one output and
the true output that the student either
passed or failed to class let's suppose
instead of computing a zero one output
now we want to
compute the actual grade that you will
get on the class so now it's not 0-1 but
it's actually a grade it could be any
number actually right now we want to use
a different loss because the output of
our net of our neural network is
different and defining losses is
actually kind of one of the arts in deep
learning so you have to define the
questions that you're asking so you can
define the loss that you need to
optimize over so here in this example
since we're not optimizing over zero one
loss we're optimizing over any real
number we're gonna use a mean squared
error loss and that's just computing the
squared error so you take the difference
between what you expect the output to be
and what you're actually output was you
take that difference you square it and
you compute the mean over your entire
population okay great
so now let's put some of this
information together we've learned how
to build neural networks we've learned
how to quantify their loss now we can
learn how to actually use that loss to
iteratively update and train the neural
network over time given some data and
essentially what this amounts to what
this boils down to is that we want to
find the weights of the neural network W
that minimize this empirical loss so
remember again the empirical loss is the
loss over the entire training set it's
the mean loss of all of the popular of
all of the individuals in the training
set and we want to minimize that loss
and that essentially means we want to
find the weights the parameterization of
the network that results in the minimum
loss remember again that W here is just
a collection it's just a set of all of
the weights in the network so before I
define W as W 0 W 1 which is the weights
for the first layer second layer third
layer etc and you keep stacking all of
these weights together you combine them
and you want to compute this
optimization problem over all of these
weights so again remember our loss
function what does our loss function
look like it's just a simple function
that takes as inputs our weights and if
we have two weights we can actually
visualize it again we can see on the
x-axis
one way so this is one scaler that we
can change and another way on the y axis
and on the z axis this is our actual
loss if we want to find the lowest point
in this landscape that corresponds to
the minimum loss and we want to find
that point so that we can find the
corresponding weights that were set to
achieve that minimum loss so how do we
do it we use this technique called loss
optimization through gradient descent we
start by picking an initial point on
this landscape an initial w0 w1 so
here's this point this black cross we
start at this point we compute the
gradient at this local point and in this
landscape we can see that the gradient
tells us the direction of maximal ascent
now that we know the direction of the
maximal ascent we can reverse that
gradient and actually take a small step
in the opposite direction that moves us
closer towards the lowest point because
we're taking a greedy approach to move
in the opposite direction of the
gradient we can iteratively repeat this
process over and over and over again we
computing the gradient at each time and
keep moving moving closer towards that
lowest minimum we can summarize this
algorithm known as gradient descent in
pseudocode by this the pseudocode on the
left-hand side we start by initializing
our weights randomly computing this
gradient DJ DW then updating our weights
in the opposite direction of that
gradient we used this small amount ADA
which you can see here and this is
essentially what we call the learning
rate this is determining how much of a
step we take and how much we trust that
with that gradient update that we
computed we'll talk more about this
later but for now let's take a look at
this term here this gradient DJ DW is
actually explaining how the lost changes
with respect to each of the weights but
I never actually told you how to compute
this term this is actually a crucial
part of deep learning and neural
networks in general
computing this term is essentially all
that matters when you try and optimize
your network is the most computational
part of training as well and it's known
as back propagation we'll start with a
very simple network with only one hidden
input sorry with one input one hidden
layer one handed and unit and one output
computing the gradient of our loss with
respect to W to corresponds to telling
us how much a small change in our and W
two affects our output or loss so if we
write this as a derivative we can start
by computing this by simply expanding
this derivative into a chain by using
the chain rule backwards from the loss
through the output and that looks like
this so DJ DW 2 becomes DJ dy dy DW 2 ok
and that's just a simple application of
the chain rule now let's suppose instead
of computing DJ DW 2 we want to compute
DJ DW 1 so I've changed the W 1 the W 2
to a W 1 on the left hand side and now
we want to compute this well we can
simply apply the chain rule again we can
take that middle term now expand it out
again using the same chain rule and back
propagate those gradients even further
back in in the network and essentially
we keep repeating this for every weight
in the network using the gradients for
later layers to back propagate those
errors back into the original input we
do this for all of the weights and and
that gives us our gradient for each
weight
yeah you're completely right so the
question is how do you ensure that this
gives you a global minimum instead of a
local minimum right so you don't we have
no guarantees on that this is not a
global minimum the whole training of
stochastic gradient sent is a greedy
optimization algorithm so you're only
taking this greedy approach and
optimizing only a local minimum there
are different ways extensions of
stochastic gradient descent that don't
take a greedy approach they take an
adaptive approach they look around a
little bit these are typically more
expensive to compute stochastic gradient
side is extremely cheap to compute in
practice and that's one of the reasons
it's used the second reason is that in
practice local minimum tend to be
sufficient so that's the back
propagation algorithm in theory it
sounds very simple it's just an
application of the chain rule but now
let's touch on some insights on training
these neural networks in practice that
makes it incredibly complex and this
gets back to that that previous point
that previous question that was raised
in practice training neural networks is
incredibly difficult this is a
visualization of the lost landscape of a
neural network in practice this is a
paper from about a year ago and the
authors visualize what a deep neural
network lost landscape really looks like
you can see many many many local minimum
here lot minimizing this loss and
finally the optimal true minimum is
extremely difficult
now recall the update equation that we
fought defined for a gradient descent
previously we take our weights and we
subtract we move towards the negative
gradient and we update our weights in
that direction I didn't talk too much
about this parameter heydo this is what
we called the learning rate I briefly
touched on it and this is essentially
determining how large of a step we take
at each iteration in practice setting
the learning rate can be extremely
difficult and actually very important
for making sure that you avoid local
minima again so if we set the learning
rate to slow then the model may get
stuck in local minimum like
this it could also converge very slowly
even in the case that it gets to a
global minimum if we set the learning
rate too large the gradients essentially
explodes and we diverge from the loss
itself and it's also been setting the
learning rate to the correct amount can
be extremely tedious in practice such
that we overshoot some of the local
minima get ourselves into a reasonable
local global minima and then converge in
within that global minima how can we do
this in a clever way so one option is
that we can try a lot of different
possible learning rates see what works
best in practice and in practice this is
actually a very common technique so a
lot of people just try a lot of learning
rates and see what works best let's see
if we can do something a bit smarter
than that as well how about we design an
adaptive algorithm that learnt that you
that adapts its learning rate according
to the lost landscape so this can take
into account the gradient at other
locations and loss it can take into
account how fast we're learning how how
large the gradient is at that location
or many other options but now since our
learning rate is not fixed for all of
the iterations of gradient descent we
have a bit more flexibility now in
learning in fact this has been widely
studied as well there are many many
different options for optimization
schemes that are present in tensorflow
and here are examples of some of them
during your labs I encourage you to try
out different of these different ones of
these optimizers and see how they're
different which works best which doesn't
work so well for your particular problem
and they're all adaptive in nature so
now I want to continue talking about
tips for training these networks in
practice and focus on the very powerful
idea of batching gradient descent and
batching your data in general so to do
this let's revisit this idea of gradient
descent very quickly so the gradient is
actually very computational to compute
this back propagation algorithm if you
want to compute it for all of the data
samples in your training data set which
may be
massive in modern data sets it's
essentially amounting to a summation
over all of these data points in most
real life problems this is extremely
computational and not feasible to
compute on every iteration so instead
people have come up with this idea of
stochastic gradient descent and that
involves picking a single point in your
data set computing the gradient with
respect to that point and then using
that to update your grade to update your
your weights so this is great because
now computing a gradient of a single
point is much easier than computing the
gradient over many points but at the
same time since we're only looking at
one point this can be extremely noisy
sure we take a different point each time
but still when we move and we take a
step in that direction of that point we
may be going in in a step that's not
necessarily representative of the entire
data set so is there a middle ground
such that we don't have to have a
stochastic a stochastic gradient but we
can still be kind of computationally
efficient in the sense so instead of
computing a noisy gradient of a single
point let's get a better estimate by
batching our data into mini batches of B
data points capital B data points so now
this gives us an estimate of the true
gradient by just averaging the gradient
from each of these points this is great
because now it's much easier to compute
than full gradient descent it's a lot
less points typically B is on the order
of less than 100 or approximately in
that range and it's a lot more accurate
than stochastic gradient descent because
you're considering a larger population
as well this increase in gradient
accuracy estimation actually allows us
to converge much quicker as well because
it means that we can increase our
learning rate and trust our gradient
more with each step which ultimately
means that we can train faster this
allows for massively parallel lyza
become potations because we can split up
batches across the GPU send batches all
over the GPU compute their gradients
simultaneously and then aggregate them
back
to even speed up even further now the
last topic I want to address before
ending is this idea of overfitting this
is one of the most fundamental problems
in machine learning as a whole not just
deep learning and at its core it
involves understanding the complexity of
your model so you want to build a model
that performs well and generalized as
well not just to your training set but
to your test set as well assume that you
want to build a model that describes
these points you can go on the left-hand
side which is just a line fitting a line
through these points this is under
fitting the complexity of your model is
not large enough to really learn the
full complexity of the data or you can
go on the right-hand side which is
overfitting where you're essentially
building a very complex model to
essentially memorize the data and this
is not useful either because when you
show a new data it's not going to sense
it's not going to perfectly match on the
training data and it means that you're
going to have high generalization error
ideally we want to end up with a model
in the middle that is not too complex to
memorize all of our training data but
still able to generalize and perform
well even we have when we have brand new
training and testing inputs so to
address this problem let's talk about
regularization for deep neural networks
deep neural regularization is a
technique that you can introduce to your
networks that will discourage complex
models from being learned and as before
we've seen that it's crucial for our
models to be able to generalize to data
beyond our training set but also to
generate generalize to data in our
testing set as well the most popular
regularization technique in deep
learning is a very simple idea called
dropout let's revisit this and a picture
of a deep neural network again and drop
out during training we randomly set some
of our activations of the hidden neurons
to 0 with some probability that's why we
call it dropping out because we're
essentially killing off those neurons so
let's do that so we kill off these
random sample of neurons
and now we've created a different
pathway through the network let's say
that you dropped 50 percent of the
neurons this means that those
activations are set to zero and the
network is not going to rely too heavily
on any particular path through the
network but it's instead going to find a
whole ensemble of different paths
because it doesn't know which path is
going to be dropped out at any given
time we repeat this process on every
training iteration now dropping out a
new set of 50 50 % of the neurons and
the result of this is essentially a
model that like I said creates an
ensemble of multiple models through the
paths of the network and is able to
generalize better to unseen test data so
the second technique for a
regularization is this notion that we'll
talk about which is early stopping and
the idea here is also extremely simple
let's train our neural network like
before no dropout but let's just stop
training before we have a chance to
overfit so we start training and the
definition of overfitting is just when
our model starts to perform worse on the
test set then on the training set so we
can start off and we can plot how our
loss is going for both the training and
test set we can see that both are
decreasing so we keep training now we
can see that the training the validation
both losses are kind of starting to
plateau here we can keep going the
training loss is always going to decay
it's always going to keep decreasing
because especially if you have a network
that is having such a large capacity to
essentially memorize your data you can
always perfectly get a training accuracy
of 0 that's not always the case but in a
lot of times with deep neural networks
since they're so expressive and have so
many weights they're able to actually
memorize the data if you let them train
for too long if we keep training like
you see the training set continues to
decrease now the validation set starts
to increase and if we keep doing this
the trend continues the idea of early
stopping is essentially that we want to
focus on this point here and stop
training when we reach this point so we
can key
basically records of the model during
training and once we start to detect
overfitting we can just stop and take
that last model that was still occurring
before the overfitting happened right so
on the left hand side you can see the
under fitting you don't want to stop too
early you want to let the model get the
minimum validation set accuracy but also
you don't want to keep training such
that the validation accuracy starts the
increase on the other end as well so
I'll conclude this first lecture by
summarizing three key points that we
have covered so far first we learned
about the fundamental building blocks of
deep learning which is just a single
neuron or called the perceptron we
learned about back propagation how to
stack these neurons into complex deep
neural networks how to back propagate
and errors through them and learn
complex loss functions and finally we
discussed some of the practical details
and tricks to training neural networks
that are really crucial today if you
want to work in this field such as
batching regularization and and others
so now I'll take any questions or if
there are no questions and I'm gonna
hand the mic over to ovah who will talk
about sequence modeling thank you
[Applause]